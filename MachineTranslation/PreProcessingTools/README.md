# AuxiliaryTools
本脚本中包含一些NLP任务中基本的操作:分句(英文)、分词(中、英)、识别语种(所有).
- [Participle_word_tool.py:](https://github.com/Shajiu/NaturalLanguageProcessing/edit/master/MachineTranslation/PreProcessingTools/dividePaper.py) 英文分词工具
- [divide_sentence.py:](https://github.com/Shajiu/NaturalLanguageProcessing/edit/master/MachineTranslation/PreProcessingTools/divideSentence.py)英文分句工具
- [jieba_fenCi.py:](https://github.com/Shajiu/NaturalLanguageProcessing/edit/master/MachineTranslation/PreProcessingTools/jiebaFenCi.py)中文分词工具
- [participle.py](https://github.com/Shajiu/NaturalLanguageProcessing/edit/master/MachineTranslation/PreProcessingTools/participle.py)英文分词工具
- [sentence_token.py:](https://github.com/Shajiu/NaturalLanguageProcessing/edit/master/MachineTranslation/PreProcessingTools/sentenceToken.py)英文分词、英文分句、中文分词、识别语种
 
