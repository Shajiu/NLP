# NLP
#### 免责声明
该项目中的内容仅供技术研究参考，不作为任何结论性依据。使用者可以在许可证范围内任意使用该模型，但我们不对因使用该项目内容造成的直接或间接损失负责。技术报告中所呈现的实验结果仅表明在特定数据集和超参组合下的表现，并不能代表各个模型的本质。 实验结果可能因随机数种子，计算设备而发生改变。
使用者以各种方式使用本模型（包括但不限于修改使用、直接使用、通过第三方使用）的过程中，不得以任何方式利用本模型直接或间接从事违反所属法域的法律法规、以及社会公德的行为。使用者需对自身行为负责，因使用本模型引发的一切纠纷，由使用者自行承担全部法律及连带责任。我们不承担任何法律及连带责任。
我们拥有对本免责声明的解释、修改及更新权。





# 本项目为多策略切分粒度的藏语文本分词系统
## 介绍
- 针对藏汉双向机器翻译的具有音节、词语以及音词融合的多粒度切分方法。
- 在CWMT2018藏汉双语数据集上的实验结果表明,多粒度训练方法的翻译效果明显优于其余切分粒度的基线系统。
## 系统说明
- models为存储分词参数文件；
- tokennizer_web.py为演示demo脚本
## 依赖环境
- python3.8+
- sentencepiece
- gradio
## Demo界面展示
<img width="1920" alt="5a7b8d74af280d0f1175fe7cadbde21" src="https://github.com/Shajiu/NaturalLanguageProcessing/assets/31726161/caa8eb4a-b3e9-4035-a438-7360ae95c959">


